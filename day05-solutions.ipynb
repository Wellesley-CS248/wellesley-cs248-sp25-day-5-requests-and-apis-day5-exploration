{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS 248 Day 5 - Exploring `requests`\n",
    "\n",
    "**Author:** Eni Mustafaraj\n",
    "**Date:** Feb 20, 2025\n",
    "\n",
    "**Table of Content**\n",
    "\n",
    "1. [Part 1: compare results from requests](#sec1)\n",
    "2. [Part 2: retrieve and save JSON data](#sec2)\n",
    "3. [Part 3: use pandas to transform our data](#sec3)\n",
    "\n",
    "These examples were initially coded live during class time, but then the notebook was edited to add text and structure for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec1\"></a>\n",
    "\n",
    "### Part 1: compare results from two requests\n",
    "\n",
    "In this part, we will send requests for two different URLs, to check whether the pages have the same content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a very simplistic solution, for speed's sake.\n",
    "# Generally, we first need to check that the response was successful\n",
    "# before we actually try to read the text from the response.\n",
    "\n",
    "import requests\n",
    "\n",
    "url1 = \"https://dish.avifoodsystems.com/wellesley\"\n",
    "url2 = \"https://dish.avifoodsystems.com/wellesley/96/148/week\"\n",
    "\n",
    "text1 = requests.get(url1).text\n",
    "text2 = requests.get(url2).text\n",
    "\n",
    "# Test if the retrieved text is the same\n",
    "text1 == text2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was unexpected. We had two different URLs, so the expectation was for the content to be different, especially since the corresponding pages on the Web look different. However, Wellesley Fresh AVI seem to use data injenction into its web pages to make them dynamic. Their website is written using Angular, a web application framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec2\"></a>\n",
    "\n",
    "### Part 2: Getting JSON data\n",
    "\n",
    "Now we will try the new URL, which is an API call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url3 = \"https://dish.avifoodsystems.com/api/menu-items/week?date=2/20/2025&locationId=96&mealId=148\"\n",
    "\n",
    "# first save the text of the response, as we did before\n",
    "text = requests.get(url3).text\n",
    "type(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result we got is a string, since that is what we asked for (text is always a string). It is possible to convert this text to a list of dictionaries (though we will show below that we don' need this, because of the `.json` method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# load a string into JSON formatted list\n",
    "data1 = json.loads(requests.get(url3).text)\n",
    "type(data1), type(data1[0]) # see that the outer structure is a list, and its elements are dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use the default method `.json` that is part of the Response object from the requests library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = requests.get(url3).json()\n",
    "type(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check if the two lists are the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 == data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore what is in these lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access one item:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use list comprehension to print out the names of all foods in the menu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meals = [item['name'] for item in data2]\n",
    "for el in meals: print(el)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of doing further work, we are going to save the data into a JSON file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lulu-menu.json\", 'w') as outf:\n",
    "    json.dump(data2, outf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec3\"></a>\n",
    "\n",
    "### Part 3: use pandas to transform our data\n",
    "\n",
    "We can use pandas with JSON files, similar to how we use pandas with CSV files.\n",
    "This makes sense only if we have a list of dictionaries, since each dictionary can be converted into a row for the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# there is a function read_json, just like there is a function read_csv\n",
    "df = pd.read_json(\"lulu-menu.json\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some of the typical exploration whenever we load a new dataset into a dataframe:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learn about the structure of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape # find the size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data types of each column\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look up only one row\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see what is stored in the column \"allergens\"\n",
    "df.iloc[0]['allergens']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a list of dictionaries. We can also find rows where this list is empty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1]['allergens'] # second row doesn't have allergens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would we go about counting how many cells are an empty list? \n",
    "Using the `apply` method, we can first find all the cells that are empty lists, and then sum their number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pandas methods to check how many rows do not have allergens, that is, are empty lists\n",
    "df['allergens'].apply(lambda x: type(x)==list and len(x) == 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why does the above code work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first just apply the lambda function to the whole column and see what the result looks like\n",
    "result = df['allergens'].apply(lambda x: type(x)==list and len(x) == 0)\n",
    "result.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cod above, the `lambda` function is a **predicate** that returns True or False. Specifically, it returns True for empty lists. \n",
    "Applying the function `sum` to the Series with this True-s and False-s, counts the number of True values, since in Python (True means 1 and False means 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning up the \"allergens\"\n",
    "\n",
    "Instead of keeping the allergen colum as is, we want to replace the lists with a string of comma separated values, and the empty list with an empty string. \n",
    "\n",
    "We can do that by creating a function `transform`, which then will be applied to every cell of the column \"allergen\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(cellLst):\n",
    "    result = \"\"\n",
    "    if cellLst:\n",
    "        result = \",\".join([item['name'] for item in cellLst])\n",
    "    return result\n",
    "\n",
    "# test it with one item from the column to see how it works\n",
    "transform(df.iloc[0].allergens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try again with a cell that has an empty list\n",
    "\n",
    "transform(df.iloc[1].allergens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we got an empty string. Now that we know that our function is doing the right thing, we will apply it to the whole column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['allergens'] = df['allergens'].apply(transform) # notice, we don't pass any arguments to the function here\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Can we use the function we just created to clean up any other columns in this table?\n",
    "\n",
    "If so, go ahead and do it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other pandas functions\n",
    "\n",
    "Let's find all the foods, whose description contains a certain word. That is, we want all dishes that contain a certain ingredient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all foods that contain eggs\n",
    "query = \"eggs\"\n",
    "filtered = df[df['description'].str.contains(query, case=False, na=False)]\n",
    "filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see these dishes\n",
    "filtered['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there is a lot of repeated rows. Are these the same items?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that row 5 and 17 have the same id value, 19874, they simply have a different date, but everything else is the same. This means that we would have to drop a lot of rows from this tables, since they are not helpful for certain kinds of analysis (though they are valuable when doing the daily menu, to know what we will eat that day)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping columns\n",
    "\n",
    "Some of the columns in this dataframe are not particulary useful, for example, image, stationName, price, etc. \n",
    "We can drop all these columns with a single command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLess = df.drop(columns=['date', 'image', 'stationName', 'stationOrder', 'price'])\n",
    "dfLess.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLess.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping duplicate rows\n",
    "\n",
    "Let's remove dishes that are repeated, given their ID, which is unique for each dish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal = dfLess.drop_duplicates(subset=['id'], keep='first')\n",
    "dfFinal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only 29 unique dishes in the data we got for Lulu & Breakfast.\n",
    "\n",
    "We will continue working with this data in the assignment for Week 5!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
